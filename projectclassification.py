# -*- coding: utf-8 -*-
"""ProjectClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VbR28Cr8Dt7KCdGvGCxeKVLeJHW-7Jv-
"""

import numpy as np
import pandas as pd
import seaborn as sb

crop=pd.read_csv("Crop_recommendation.csv")

df = pd.DataFrame(crop)

sb.boxplot(df["N"])

df.info()

df.head()

sb.heatmap(df.isnull())

# df_label = pd.get_dummies(df['label'])
# df = pd.concat([df,df_label],axis=1)

"""Converting Crops to Numbers"""

cropNames = df['label'].value_counts().to_dict()

NumAndCrops = {}
a=0
for i in cropNames:
  NumAndCrops[a]=i
  a+=1
NumAndCrops

df_crops = pd.DataFrame(NumAndCrops.items(),columns=['cropNo','label'])
df_crops

df = pd.merge(df,df_crops,on='label')
df.head(10)

df.drop(df.columns[-2],axis=1,inplace = True)
df.head()

target = df['cropNo']
features = df[['N','P','K','temperature','humidity','ph','rainfall']]

"""Splitting Dataset"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

X_train, X_test, y_train, y_test = train_test_split(features,target,test_size=0.2,random_state=42)

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

"""Decision Tree"""

from sklearn import tree

# trialScores = {}
# for i in range(1,101):
#   dt_clf = tree.DecisionTreeClassifier(max_depth=i)
#   dt_clf.fit(X_train, y_train)
#   trialScores[i] = dt_clf.score(X_test,y_test)

# ts = list(trialScores.values())
# plt.plot(ts)

# trialScores

dt_clf = tree.DecisionTreeClassifier(max_depth=10)
dt_clf.fit(X_train, y_train)
dt_clf.score(X_test,y_test)

y_pred = dt_clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

"""Random Forest Classifier

"""

from sklearn.ensemble import RandomForestClassifier

# trialScores = {}
# for i in range(1,101):
#   rf_clf = RandomForestClassifier(n_estimators=i)
#   rf_clf.fit(X_train, y_train)
#   trialScores[i] = rf_clf.score(X_test, y_test)

# ts = list(trialScores.values())
# plt.plot(ts)

# trialScores

rf_clf = RandomForestClassifier(n_estimators=20)
rf_clf.fit(X_train, y_train)
rf_clf.score(X_test, y_test)

y_pred = rf_clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

importance = rf_clf.feature_importances_
columns = features.columns

rf_clf_cof = pd.Series(importance,columns)

rf_clf_cof

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
rf_clf_cof.plot(kind="bar", figsize=(10,5))
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

import seaborn as sb
from sklearn.utils.multiclass import unique_labels

sb.set(rc = {'figure.figsize':(15,8)})
def plotConfusionMatrix(y_test,y_pred):
  labels = unique_labels(y_test)
  columns = [f'predicted {label}' for label in labels]
  index = [f'actual {label}' for label in labels]
  table = pd.DataFrame(confusion_matrix(y_test,y_pred),columns=columns,index=index)
  return sb.heatmap(table,annot=True,fmt='d',cmap='viridis')
plotConfusionMatrix(y_test,y_pred)

"""k means"""

from sklearn.neighbors import KNeighborsClassifier

# trialScores = {}
# for i in range(1,51):
#   knn_clf = KNeighborsClassifier(n_neighbors=i)
#   knn_clf.fit(X_train,y_train)
#   trialScores[i]= knn_clf.score(X_test,y_test)

# ts = list(trialScores.values())
# plt.plot(ts)

# trialScores

knn_clf = KNeighborsClassifier(n_neighbors=4)
knn_clf.fit(X_train,y_train)
knn_clf.score(X_test,y_test)

y_pred = knn_clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm